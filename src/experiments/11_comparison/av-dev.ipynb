{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import julia\n",
    "julia.install()\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# # Point to the top of the project relative to this script\n",
    "def projectdir(*args):\n",
    "    return str(Path.cwd().joinpath(\"..\", \"..\", \"..\", *args).resolve())\n",
    "\n",
    "def print_allocated_memory():\n",
    "   print(\"{:.2f} GB\".format(torch.cuda.memory_allocated() / 1024 ** 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00 GB\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from julia import Main as jl\n",
    "from sklearn.metrics import accuracy_score\n",
    "import ipdb\n",
    "import torch\n",
    "# from torchvision.transforms import Lambda\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torchvision.models import resnet50\n",
    "from torchvision.models import ResNet50_Weights\n",
    "from torchvision import models\n",
    "from torchvision.models.feature_extraction import create_feature_extractor\n",
    "\n",
    "class DDVFAStrategy():\n",
    "    \"\"\"DDVFA Strategy\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        jl.project_dir = projectdir()\n",
    "        jl.eval(\"using Pkg; Pkg.activate(project_dir)\")\n",
    "        jl.eval(\"using AdaptiveResonance\")\n",
    "        jl.eval(\"art = DDVFA(rho_lb=0.4, rho_ub=0.75)\")\n",
    "        # jl.eval(\"art.config = DataConfig(0.0, 255.0, 28*28)\")\n",
    "        jl.eval(\"art.config = DataConfig(0, 1.0, 49)\")\n",
    "        \n",
    "        rn = resnet50()\n",
    "        self.mod = create_feature_extractor(rn, {'layer4': 'layer4'})\n",
    "        self.mod = self.mod.to('cuda')\n",
    "        self.mod.eval()\n",
    "        self.weights = ResNet50_Weights.DEFAULT\n",
    "        self.preprocess = self.weights.transforms()\n",
    "        self.min = 10.0\n",
    "        self.max = 70.0\n",
    "\n",
    "    def ext_features(self, img):\n",
    "        # print(rgbimg.shape)\n",
    "        # prep = self.preprocess(rgbimg)\n",
    "        img = img.to('cuda')\n",
    "        prep = self.preprocess(img)\n",
    "        features = self.mod(prep)['layer4']\n",
    "        # avg_features = features.mean(dim=1).flatten(start_dim=1).detach().cpu().numpy()\n",
    "        avg_features = features.detach().mean(dim=1).flatten(start_dim=1)\n",
    "        avg_features = (avg_features - self.min) / (self.max - self.min) * 2 - 1\n",
    "        avg_features = avg_features.sigmoid().cpu().numpy()\n",
    "        # avg_features = features.mean(dim=1).flatten(start_dim=1).cpu().numpy()\n",
    "        # ipdb.set_trace()\n",
    "        # avg_features.flatten().detach().numpy()\n",
    "        return avg_features\n",
    "\n",
    "    def train(self, experience):\n",
    "        train_dataset = experience.dataset\n",
    "        t = experience.task_label\n",
    "        train_data_loader = DataLoader(\n",
    "            # train_dataset,\n",
    "            dataset=train_dataset,\n",
    "            pin_memory=True,\n",
    "            # num_workers=1,\n",
    "            # num_workers=4,\n",
    "            # batch_size=64,\n",
    "            batch_size=90,\n",
    "            # transform=self.trans\n",
    "        )\n",
    "        print(experience.dataset.__len__())\n",
    "        for mb in tqdm(train_data_loader):\n",
    "            # ld = mb[0].to('cuda')\n",
    "            data, labels, tasks = mb\n",
    "            af = self.ext_features(data)\n",
    "            jl.features = af\n",
    "            jl.labels = labels.numpy()\n",
    "            # ipdb.set_trace()\n",
    "            jl.eval(\"train!(art, features, y=labels)\")\n",
    "            # for sample, label, task in mb:\n",
    "            # for sample in mb:\n",
    "            #     self.ext_features(sample)\n",
    "\n",
    "        # for sample in train_dataset:\n",
    "        # n_samples = len(train_dataset)\n",
    "        # for ix in range(n_samples):\n",
    "        # for ix in tqdm(range(n_samples)):\n",
    "            # ls, ll, lt = train_dataset[ix]\n",
    "            # self.ext_features(ls)\n",
    "            # self.model(ls)\n",
    "\n",
    "            # # ipdb.set_trace()\n",
    "            # jl.sample = ls.flatten().numpy()\n",
    "            # jl.label = ll\n",
    "            # jl.t = lt\n",
    "            # jl.eval(\"train!(art, sample, y=label)\")\n",
    "\n",
    "    def eval(self, experience):\n",
    "        eval_dataset = experience.dataset\n",
    "        t = experience.task_label\n",
    "        # eval_data_loader = DataLoader(\n",
    "        #     # eval_dataset, num_workers=4, batch_size=128\n",
    "        #     eval_dataset, num_workers=4, batch_size=32\n",
    "        # )\n",
    "        # print(eval_data_loader)\n",
    "\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        # for mb in eval_data_loader:\n",
    "        #     for sample, label in mb:\n",
    "        #         jl.sample = sample.transpose()\n",
    "        #         jl.label = label.numpy()\n",
    "        #         y_hat = jl.eval(\"classify(art, sample)\")\n",
    "\n",
    "        eval_data_loader = DataLoader(\n",
    "            # train_dataset,\n",
    "            dataset=train_dataset,\n",
    "            pin_memory=True,\n",
    "            # num_workers=1,\n",
    "            # num_workers=4,\n",
    "            # batch_size=64,\n",
    "            batch_size=90,\n",
    "            # transform=self.trans\n",
    "        )\n",
    "        print(experience.dataset.__len__())\n",
    "        for mb in tqdm(train_data_loader):\n",
    "            # ld = mb[0].to('cuda')\n",
    "            data, labels, tasks = mb\n",
    "            af = self.ext_features(data)\n",
    "            jl.features = af\n",
    "            jl.labels = labels.numpy()\n",
    "            # ipdb.set_trace()\n",
    "            y_hats = jl.eval(\"train!(art, features, y=labels)\")\n",
    "            correct = torch.sum(y_hats == labels)\n",
    "\n",
    "            # total += 1\n",
    "            # if y_hat == label:\n",
    "            #     correct += 1\n",
    "        \n",
    "        return correct/total\n",
    "        # j.samples = mb\n",
    "        # y_hats = j.eval(\"classify(art, samples)\")\n",
    "        # accuracy_score(y_test, y_hat)\n",
    "\n",
    "print_allocated_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experiment...\n",
      "Start of experience  0\n",
      "12188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████▏    | 70/136 [00:20<00:19,  3.39it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mStart of experience \u001b[39m\u001b[39m\"\u001b[39m, experience\u001b[39m.\u001b[39mcurrent_experience)\n\u001b[0;32m     23\u001b[0m     \u001b[39m# print(experience.dataset)\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m     cl_strategy\u001b[39m.\u001b[39;49mtrain(experience)\n\u001b[0;32m     25\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mTraining completed\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     27\u001b[0m \u001b[39m#     print('Computing accuracy on the current test set')\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[39m#     cl_strategy.eval(benchmark.test_stream[exp_id])\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[39m# features.mean(dim=1).flatten(start_dim=1).detach().cpu().numpy()\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[39m# features.mean(dim=1).flatten(start_dim=1)\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[39m# def lin_normalize()\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[2], line 68\u001b[0m, in \u001b[0;36mDDVFAStrategy.train\u001b[1;34m(self, experience)\u001b[0m\n\u001b[0;32m     66\u001b[0m af \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mext_features(data)\n\u001b[0;32m     67\u001b[0m jl\u001b[39m.\u001b[39mfeatures \u001b[39m=\u001b[39m af\n\u001b[1;32m---> 68\u001b[0m jl\u001b[39m.\u001b[39;49mlabels \u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39mnumpy()\n\u001b[0;32m     69\u001b[0m \u001b[39m# ipdb.set_trace()\u001b[39;00m\n\u001b[0;32m     70\u001b[0m jl\u001b[39m.\u001b[39meval(\u001b[39m\"\u001b[39m\u001b[39mtrain!(art, features, y=labels)\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from avalanche.benchmarks import SplitMNIST\n",
    "from avalanche.benchmarks.classic import SplitCIFAR10\n",
    "from torchvision.transforms import Lambda\n",
    "\n",
    "trans = Lambda(lambda x: x.repeat(3, 1, 1) if x.size(0)==1 else x)\n",
    "# Benchmark creation\n",
    "benchmark = SplitMNIST(\n",
    "    n_experiences=5,\n",
    "    train_transform=trans,\n",
    "    eval_transform=trans,\n",
    ")\n",
    "# benchmark = SplitCIFAR10(n_experiences=5, return_task_id=True)\n",
    "\n",
    "# Create the Strategy Instance\n",
    "cl_strategy = DDVFAStrategy()\n",
    "\n",
    "# Training Loop\n",
    "print('Starting experiment...')\n",
    "\n",
    "for exp_id, experience in enumerate(benchmark.train_stream):\n",
    "    print(\"Start of experience \", experience.current_experience)\n",
    "\n",
    "    # print(experience.dataset)\n",
    "    cl_strategy.train(experience)\n",
    "    print('Training completed')\n",
    "\n",
    "    print('Computing accuracy on the current test set')\n",
    "    cl_strategy.eval(benchmark.test_stream[exp_id])\n",
    "# features.mean(dim=1).flatten(start_dim=1).detach().cpu().numpy()\n",
    "# features.mean(dim=1).flatten(start_dim=1)\n",
    "# def lin_normalize()\n",
    "# min = 10\n",
    "# max = 70\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[15.9900,  3.4863,  7.3100],\n",
      "        [ 4.1277,  1.6839, 16.4035]], dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.9900, -6.5137, -2.6900],\n",
       "        [-5.8723, -8.3161,  6.4035]], dtype=torch.float64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.rand((2, 3), dtype=torch.float64) * 20.\n",
    "print(b)\n",
    "b - 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m inp \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandn(\u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m224\u001b[39m, \u001b[39m224\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m model(inp)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "inp = torch.randn(2, 3, 224, 224)\n",
    "model(inp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "avalanche",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
