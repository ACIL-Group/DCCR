{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--cuda CUDA]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --ip=127.0.0.1 --stdin=9014 --control=9012 --hb=9011 --Session.signature_scheme=\"hmac-sha256\" --Session.key=b\"7f7192da-c8f1-4c22-a9f8-bc03ada51756\" --shell=9013 --transport=\"tcp\" --iopub=9015 --f=c:\\Users\\Sasha\\AppData\\Roaming\\jupyter\\runtime\\kernel-v2-2656ZiSZLbhkZwG5.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sasha\\Anaconda3\\envs\\avalanche\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3468: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This example trains on Split CIFAR10 with Naive strategy.\n",
    "In this example each experience has a different task label.\n",
    "We use a multi-head model with a separate classifier for each task.\n",
    "\"\"\"\n",
    "\n",
    "import argparse\n",
    "import torch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "\n",
    "from avalanche.benchmarks.classic import SplitCIFAR10\n",
    "from avalanche.models import SimpleMLP, as_multitask\n",
    "from avalanche.training.supervised import Naive\n",
    "\n",
    "\n",
    "def main(args):\n",
    "\n",
    "    # model\n",
    "    model = SimpleMLP(input_size=32 * 32 * 3, num_classes=10)\n",
    "    model = as_multitask(model, \"classifier\")\n",
    "\n",
    "    # CL Benchmark Creation\n",
    "    benchmark = SplitCIFAR10(n_experiences=5, return_task_id=True)\n",
    "    train_stream = benchmark.train_stream\n",
    "    test_stream = benchmark.test_stream\n",
    "\n",
    "    # Prepare for training & testing\n",
    "    optimizer = Adam(model.parameters(), lr=0.01)\n",
    "    criterion = CrossEntropyLoss()\n",
    "\n",
    "    # Choose a CL strategy\n",
    "    strategy = Naive(\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        criterion=criterion,\n",
    "        train_mb_size=128,\n",
    "        train_epochs=3,\n",
    "        eval_mb_size=128,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    # train and test loop\n",
    "    for train_task in train_stream:\n",
    "        strategy.train(train_task, num_workers=0)\n",
    "        strategy.eval(test_stream)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        \"--cuda\",\n",
    "        type=int,\n",
    "        default=0,\n",
    "        help=\"Select zero-indexed cuda device. -1 to use CPU.\",\n",
    "    )\n",
    "    args = parser.parse_args()\n",
    "    main(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from avalanche.benchmarks import SplitMNIST\n",
    "# from avalanche.benchmarks.utils.data_loader import GroupBalancedDataLoader\n",
    "from avalanche.benchmarks.utils.data_loader import TaskBalancedDataLoader\n",
    "benchmark = SplitMNIST(5, return_task_id=True)\n",
    "\n",
    "dl = TaskBalancedDataLoader([exp.dataset for exp in benchmark.train_stream], batch_size=4)\n",
    "for x, y, t in dl:\n",
    "    print(t.tolist())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.io import read_image\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "\n",
    "# img = read_image(\"test/assets/encode_jpeg/grace_hopper_517x606.jpg\")\n",
    "img = read_image(\"grace_hopper_517x606.jpg\")\n",
    "\n",
    "# Step 1: Initialize model with the best available weights\n",
    "weights = ResNet50_Weights.DEFAULT\n",
    "model = resnet50(weights=weights)\n",
    "model.eval()\n",
    "\n",
    "# Step 2: Initialize the inference transforms\n",
    "preprocess = weights.transforms()\n",
    "\n",
    "# Step 3: Apply inference preprocessing transforms\n",
    "batch = preprocess(img).unsqueeze(0)\n",
    "\n",
    "# Step 4: Use the model and print the predicted category\n",
    "prediction = model(batch).squeeze(0).softmax(0)\n",
    "class_id = prediction.argmax().item()\n",
    "score = prediction[class_id].item()\n",
    "category_name = weights.meta[\"categories\"][class_id]\n",
    "print(f\"{category_name}: {100 * score:.1f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "avalanche",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
